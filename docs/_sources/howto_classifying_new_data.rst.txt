HOWTO: Applying the trained PACMan model to unclassified data
=============================================================

The goal of this notebook is demonstrate the steps required to apply a
pre-trained classification model to unclassified proposals. We will
start with raw proposal data located in ``proposal_data`` directory and
perform the following steps:

1. Proposal Scraping

   -  Extracting the Abstract and Scientific Justification sections from
      the .txtx files generated by the PDF to ascii converter

2. Text Preprocessing

   -  Tokenization
   -  Filtering stop words
   -  Lemmatization

3. Applying the model on a set of unclassified proposals

.. code:: ipython3

    # native python
    import os
    import sys
    cwd = os.getcwd()
    pacman_directory = os.path.join('/',*cwd.split('/')[:-1])
    sys.path.append(pacman_directory)
    
    # open source packages
    import matplotlib.pyplot as plt
    plt.style.use('ggplot')
    import numpy as np
    import pandas as pd
    
    # custom packages that are all in the github repo
    from pacman2020 import PACManPipeline
    from utils.proposal_scraper import HSTProposalScraper
    # from utils.analyzer import PACManAnalyze

1. Proposal Scraping
~~~~~~~~~~~~~~~~~~~~

Again, we use the ``HSTProposalScraper`` class to extract the Abstract
and Scientific Jusitication sections of the HST proposals. For this
example, we are going to be scraping unclassified proposals from Cycle
23.

-  By setting ``for_training=False``, the software will save the results
   of the scraping in
   ``~/PACMan_dist/unclassified_proposals/corpus_cy23``.

.. code:: ipython3

    pacman_scraper = HSTProposalScraper(for_training=False, cycles_to_analyze=[28])
    pacman_scraper.scrape_cycles()

2. Text Preprocessing
~~~~~~~~~~~~~~~~~~~~~

We create an instance of the ``PACManPipeline()`` class, which is a
subclass of the ``PACManTokenzier``. So just like the ``PACManTrain``
class, we have access to all the functionality required to handle the
text pre-processing.

For handling unclassified data, we provide functionality for restricting
the total number of proposals analyzed. If no value is passed, the
entire dataset will be read in. In the example below, we will only
analyze the first 30 proposals from Cycle 23.

.. code:: ipython3

    pacman_pipeline = PACManPipeline(cycle=28, model_name='pacman_production_model.joblib')
    pacman_pipeline.read_unclassified_data(N=30)

Just like in the ``PACManTrain`` class, the DataFrame containing the
proposal data is stored in a dictonary. The main difference here is the
resulting DataFrame will no longer have a column for the hand
classification or the encoded hand classification.

.. code:: ipython3

    pacman_pipeline.proposal_data.keys()

3. Applying the Model
~~~~~~~~~~~~~~~~~~~~~

Now that we have read in 30 proposals from Cycle 23, we are going to
load the classifier, ``example_pacman_model.joblib``, and use it to make
predictions. THe results will be stored in the DataFrame in the
``PACManPipeline.model_results`` attribute.

.. code:: ipython3

    pacman_pipeline.load_model()

With the classifier loaded, we are now in a position to apply the model
to the unclassified proposal data to make some predictions. The end
results will another DataFrame containing the results of the
classification.

.. code:: ipython3

    proposal_data = pacman_pipeline.proposal_data['cycle_28']

.. code:: ipython3

    proposal_data.head()

.. code:: ipython3

    test_df = proposal_data[proposal_data['proposal_num'] == 215]

.. code:: ipython3

    test_df

.. code:: ipython3

    test_df['cleaned_text'].iloc[0]

.. code:: ipython3

    pacman_pipeline.apply_model(test_df, training=False)
    pacman_pipeline.model_results

.. code:: ipython3

    for col in pacman_pipeline.model_results.columns:
        if 'prob' in col:
            print(f"{col.replace('_', ' ')}\n{pacman_pipeline.model_results[col].iloc[0]:.2%}\n{'-'*50}")
        else:
            print(f"{col.replace('_', ' ')}\n{pacman_pipeline.model_results[col].iloc[0]}\n{'-'*50}")


.. code:: ipython3

    pacman_pipeline.model_results.head()

Identify the unprocessed prosposals and copy them into a separate
directory

.. code:: ipython3

    import glob
    master_flist = glob.glob('/Users/nmiles/PACMan_dist/proposal_data/Cy28_proposals_txt/*pdf')
    proposal_nums = [val.split('/')[-1].split('.')[0] for val in master_flist]
    print(len(proposal_nums))
    processed_proposals = [val.split('/')[-1].split('.')[0] for val in pacman_pipeline.model_results['fname']]
    print(len(processed_proposals))
    unprocessed = set(proposal_nums).difference(set(processed_proposals))
    
    outdir = '/Users/nmiles/PACMan_dist/proposal_data/Cy28_unprocessed_proposals/'
    for val in unprocessed:
        for f in master_flist:
            if str(val) in f:
                print(f)
                os.system(f"cp -v {f} {outdir}/{os.path.basename(f)}")

Load in the category information

.. code:: ipython3

    flist = glob.glob('/Users/nmiles/PACMan_dist/unclassified_proposals/corpus_cy28/*parsed_text_keywords.txt')
    d = {'proposal_num':[], 'category':[], 'keyword':[]}
    for f in flist:
        proposal_num = f.split('/')[-1].split('.')[0]
        d['proposal_num'].append(proposal_num)
        with open(f, 'r') as fobj:
            lines = fobj.readlines()
    #         print(lines)
        d['category'].append(lines[0].replace('Scientific Category','').strip('\n').strip())
        d['keyword'].append(lines[1].replace('Scientific Keywords','').strip('\n').strip())
        
            

.. code:: ipython3

    proposal_label = pd.DataFrame(d)

.. code:: ipython3

    proposal_label['category'].value_counts()

.. code:: ipython3

    pacman_pipeline.model_results['model_classification'].value_counts()

.. code:: ipython3

    pacman_pipeline.model_results['proposal_num'] = [f.split('/')[-1].split('.')[0] for f in pacman_pipeline.model_results['fname']]

.. code:: ipython3

    merged_df = pacman_pipeline.model_results.merge(proposal_label, on='proposal_num')

.. code:: ipython3

    merged_df.columns

.. code:: ipython3

    merged_df.loc[:10,['model_classification','category','keyword']]

.. code:: ipython3

    output_format = ['fname','proposal_num','model_classification','category', 'keyword'] + [val for val in merged_df.columns if 'prob' in val]

.. code:: ipython3

    merged_df['proposal_num'] = list(map(int, merged_df['proposal_num']))
    merged_df = merged_df.loc[:,list(output_format)]
    merged_df.to_csv('cycle_28_pacman_predicitions.txt', header=True, index=False)

.. code:: ipython3

    merged_df.info()

.. code:: ipython3

    merged_df['proposal_num']
