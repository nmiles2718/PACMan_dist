HOWTO: Applying the trained PACMan model to unclassified data
=============================================================

The goal of this notebook is demonstrate the steps required to apply a
pre-trained classification model to unclassified proposals. We will
start with raw proposal data located in ``proposal_data`` directory and
perform the following steps:

1. Proposal Scraping

   -  Extracting the Abstract and Scientific Justification sections from
      the .txtx files generated by the PDF to ascii converter

2. Text Preprocessing

   -  Tokenization
   -  Filtering stop words
   -  Lemmatization

3. Applying the model on a set of unclassified proposals

.. code:: ipython3

    # native python
    import os
    import sys
    cwd = os.getcwd()
    pacman_directory = os.path.join('/',*cwd.split('/')[:-1])
    sys.path.append(pacman_directory)
    
    # open source packages
    import matplotlib.pyplot as plt
    plt.style.use('ggplot')
    import numpy as np
    import pandas as pd
    
    # custom packages that are all in the github repo
    from pacman2020 import PACManPipeline
    from utils.proposal_scraper import HSTProposalScraper
    # from utils.analyzer import PACManAnalyze

1. Proposal Scraping
~~~~~~~~~~~~~~~~~~~~

Again, we use the ``HSTProposalScraper`` class to extract the Abstract
and Scientific Jusitication sections of the HST proposals. For this
example, we are going to be scraping unclassified proposals from Cycle
23.

-  By setting ``for_training=False``, the software will save the results
   of the scraping in
   ``~/PACMan_dist/unclassified_proposals/corpus_cy23``.

.. code:: ipython3

    pacman_scraper = HSTProposalScraper(for_training=False, cycles_to_analyze=[23])
    pacman_scraper.scrape_cycles()


.. parsed-literal::

    INFO [proposal_scraper.scrape_cycles:546] /Users/nmiles/PACMan_dist/proposal_data/Cy23_proposals_txt/*txtx
    INFO [proposal_scraper.scrape_cycles:549] Found 1116 proposals to scrape
    Scraping Proposals: 100%|██████████| 1116/1116 [00:02<00:00, 430.62it/s]


2. Text Preprocessing
~~~~~~~~~~~~~~~~~~~~~

We create an instance of the ``PACManPipeline()`` class, which is a
subclass of the ``PACManTokenzier``. So just like the ``PACManTrain``
class, we have access to all the functionality required to handle the
text pre-processing.

For handling unclassified data, we provide functionality for restricting
the total number of proposals analyzed. If no value is passed, the
entire dataset will be read in. In the example below, we will only
analyze the first 30 proposals from Cycle 23.

.. code:: ipython3

    pacman_pipeline = PACManPipeline(cycle=23, model_name='example_pacman_model.joblib')
    pacman_pipeline.read_unclassified_data(N=30)


.. parsed-literal::

    INFO [pacman2020.read_unclassified_data:319] Reading in 30 proposals...
    Data Directory: /Users/nmiles/PACMan_dist/unclassified_proposals/corpus_cy23
    100%|██████████| 30/30 [00:21<00:00,  1.37it/s]
    INFO [pacman2020.preprocess:290] Total time for preprocessing: 0.365


Just like in the ``PACManTrain`` class, the DataFrame containing the
proposal data is stored in a dictonary. The main difference here is the
resulting DataFrame will no longer have a column for the hand
classification or the encoded hand classification.

.. code:: ipython3

    pacman_pipeline.proposal_data.keys()




.. parsed-literal::

    dict_keys(['cycle_23'])



3. Applying the Model
~~~~~~~~~~~~~~~~~~~~~

Now that we have read in 30 proposals from Cycle 23, we are going to
load the classifier, ``example_pacman_model.joblib``, and use it to make
predictions. THe results will be stored in the DataFrame in the
``PACManPipeline.model_results`` attribute.

.. code:: ipython3

    pacman_pipeline.load_model()


.. parsed-literal::

    INFO [pacman2020.load_model:231] Loading model stored at 
     /Users/nmiles/PACMan_dist/models/example_pacman_model.joblib
    INFO [pacman2020.load_model:234] Loading encoder information...


With the classifier loaded, we are now in a position to apply the model
to the unclassified proposal data to make some predictions. The end
results will another DataFrame containing the results of the
classification.

.. code:: ipython3

    pacman_pipeline.apply_model(pacman_pipeline.proposal_data['cycle_23'], training=False)
    pacman_pipeline.model_results.info()


.. parsed-literal::

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 30 entries, 0 to 29
    Data columns (total 10 columns):
    fname                                                30 non-null object
    encoded_model_classification                         30 non-null int64
    model_classification                                 30 non-null object
    galaxies_and_the_igm_prob                            30 non-null float64
    large_scale_structure_of_the_universe_prob           30 non-null float64
    planets_and_planet_formation_prob                    30 non-null float64
    solar_system_prob                                    30 non-null float64
    stellar_physics_prob                                 30 non-null float64
    stellar_populations_and_the_ism_prob                 30 non-null float64
    supermassive_black_holes_and_active_galaxies_prob    30 non-null float64
    dtypes: float64(7), int64(1), object(2)
    memory usage: 2.5+ KB


.. code:: ipython3

    pacman_pipeline.save_model_results(fout="example_pacman_model_results.txt", training=False)
