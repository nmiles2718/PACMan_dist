{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOWTO: PACMan Model Training/Testing\n",
    "\n",
    "The goal of this notebook is demonstrate the steps required to train a new multinomial, Naive Bayes classification model.\n",
    "We will start with raw proposal data located in `proposal_data` directory and perform the following steps:\n",
    "\n",
    "1. Proposal Scraping\n",
    "  1. Extracting the Abstract and Scientific Justification sections from the .txtx files generated by the PDF to ascii converter\n",
    "1. Text pre-processing\n",
    "  1. Tokenization\n",
    "  1. Filtering stop words\n",
    "  1. Lemmatization\n",
    "1. Training the model on our hand classified proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "pacman_directory = os.path.join('/',*cwd.split('/')[:-1])\n",
    "sys.path.append(pacman_directory)\n",
    "\n",
    "from pacman2020 import PACManTrain, PACManPipeline\n",
    "from utils.proposal_scraper import HSTProposalScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Proposal Scraping\n",
    "We use the `HSTProposalScraper` class contained in the `proposal_scraper` module in the `utils` subpackage. We specify that we are scraping the proposals with the intention of using them for training and that we only want to scrape proposals in Cycle 24.\n",
    "- By setting `for_training=True`, the software automatically looks for a file containing the hand classifications for the list of proposals and saves the scraped proposal information in an subdirectory of `~/PACMan_dist/training_data/`. In this example, the subdirectory will be named `training_corpus_cy24` and it will contain all of the training data for the given cycle, as well as the file containing the hand classifications.\n",
    "- For the hand classifications, we adopt the following naming convention: cycle_CYCLENUMBER_hand_classifications.txt\n",
    "   - e.g. cycle_24_hand_classifications.txt contains the hand classification of each proposal for cycle 24.\n",
    "- Additionally, the file should only contain two columns, `proposal_num` and `hand_classification`. Below is an example snippet of what the file should look like:\n",
    "    \n",
    "    ```text\n",
    "    proposal_num,hand_classification\n",
    "    0001,stellar physics\n",
    "    0002,stellar physics\n",
    "            .\n",
    "            . \n",
    "            .\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_scraper = HSTProposalScraper(for_training=True, cycles_to_analyze=[24, 25])\n",
    "pacman_scraper.scrape_cycles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../training_data/training_corpus_cy24/ | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text Preprocessing\n",
    "The `PACManTrain` class contained in the `pacman2020` module to is capable of performing all of the necessary preprocessing steps. Just like before, we specify the cycles we want to analyze and in this case it is just cycle 24.\n",
    "\n",
    "In summary, this step is processing each input proposal with the `spaCy` NLP package to generate a `Doc` object, which is a sequence of tokens. Each token is an individual word that contains a variety of semantic information derived from the word and its context in a sentence. We leverage this information to filter out stop words, punctuations,  etc... This is the slowest step of the entire process and if needed, it can be improved using the multithreading behavior of `spaCy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training = PACManTrain(cycles_to_analyze=[24])\n",
    "pacman_training.read_training_data(parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each proposal cycle in the `cycle_to_analyze` argument, the tokenizer will perform the necessary preprocessing steps and save the proposal number, text, cleaned text, filename, the hand classified science category, and the encoded value of the hand classified category. The results are stored in a pandas DataFrame in the `PACManTrain.proposal_data` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pacman_training.proposal_data.keys())\n",
    "pacman_training.proposal_data['cycle_24'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the resulting DataFrame to make a quickplot of the distribution of proposal categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_categories = pacman_training.proposal_data['cycle_24']['hand_classification'].value_counts()\n",
    "print(proposal_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "\n",
    "Now that we have all the proposal information loaded, we can train our Multinomial Naive Bayes classifier. When no model or vectorizer is specified, the software will use the default classifier (Multinomial Naive Bayes) and the default vectorizer (term frequency-inverse document frequency TFIDF). In theory, you can pass any classifier and any vectorizer you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training.fit_model(pacman_training.proposal_data[\"cycle_24\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_pipeline = PACManPipeline(cycle=25, model_name='pacman_production_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO [pacman2020.read_data:311] Reading in 30 proposals...\n",
      "Data Directory: /user/nmiles/PACMan_dist/unclassified_proposals/corpus_cy25\n",
      "0it [00:00, ?it/s]\n",
      "INFO [pacman2020.preprocess:282] Total time for preprocessing: 0.000\n"
     ]
    }
   ],
   "source": [
    "pacman_pipeline.read_data(cycle=25, N=30, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
